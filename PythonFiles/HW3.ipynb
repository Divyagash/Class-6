{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Neuralnets(object):\n",
    "    \n",
    "    def __init__(self,classes):\n",
    "        self.classes = classes\n",
    "        \n",
    "    \n",
    "    # Initialize the weights as a numpy array (All weights will be matrices)\n",
    "    # Initialize the bias terms as a numpy array as well (Bias terms will be vectors)\n",
    "    \n",
    "    def buildNeuralNetworks(self,X,y,hL,nodes,iteration,eta):\n",
    "        # SGD\n",
    "        parameters = self.ParameterInitialization(X,y,nodes)\n",
    "        weightStorage = parameters[0]\n",
    "        biasStorage = parameters[1]\n",
    "        for i in xrange(0,iteration):\n",
    "            np.random.shuffle(X)\n",
    "            samples,featuress = X.shape\n",
    "            for j in xrange(0,samples):\n",
    "                x = X[j,]\n",
    "            \n",
    "                # Feed Forward\n",
    "                # Store W,a,f'(z)\n",
    "                #weightStorage = np.empty()\n",
    "                valueStorage = []\n",
    "                activeDerivStorage = []\n",
    "                #a = x\n",
    "                valueStorage.append(x)\n",
    "                #print x\n",
    "                for k in range(hL+1):\n",
    "                    #print k\n",
    "                    #print a\n",
    "                    #print weightStorage[k]\n",
    "                    #print valueStorage[k]\n",
    "                    #print biasStorage[k]\n",
    "                    z =np.dot(np.transpose(weightStorage[k]),valueStorage[k]) +biasStorage[k]\n",
    "                    #print '--z-value--'\n",
    "                    #print z\n",
    "                    if k != hL:\n",
    "                        #print z\n",
    "                        f = np.vectorize(self.ReLU)\n",
    "                        a = f(z)\n",
    "                        \n",
    "                        #print '--a-value--'\n",
    "                        #print a.shape\n",
    "                        #print a\n",
    "                        \n",
    "                        valueStorage.append(a)\n",
    "                        #print valueStorage.shape\n",
    "                        fPrime = np.vectorize(self.ReLUDeriv)\n",
    "                        activeDerivStorage.append(fPrime(z))\n",
    "                    else:\n",
    "                        #f = np.vectorize(self.softmax)\n",
    "                        a = self.softmax(z)\n",
    "                        #print '--a-value--'\n",
    "                        #print a.shape\n",
    "                        #print a\n",
    "                        valueStorage.append(a)\n",
    "                        #fPrime = np.vectorize(self.softmaxDeriv)\n",
    "                        activeDerivStorage.append(self.softmaxDeriv(z))\n",
    "                \n",
    "                #print y[j]\n",
    "                #print valueStorage[hL+1]\n",
    "                #print valueStorage\n",
    "                #print len(valueStorage)\n",
    "                \n",
    "                #lossDeriv = self.crossEntropyLoss(y[j],valueStorage[hL+1]) # Use the value from the output layer (last)\n",
    "                \n",
    "                # diagonal of the softmax matrix to calculate the output error\n",
    "                # Use the entire matrix of softmax Jacobian for this purpose\n",
    "                #print lossDeriv\n",
    "                #print z\n",
    "                \n",
    "                #outputError = np.dot(self.softmaxDeriv(z),np.transpose(lossDeriv))\n",
    "                outputError =  valueStorage[hL+1] - y[j]\n",
    "                #print outputError\n",
    "                #print outputError\n",
    "                #print np.dot(self.softmaxDeriv(z),np.transpose(lossDeriv))\n",
    "                #print self.softmaxDeriv(z)\n",
    "                \n",
    "                #print np.transpose(lossDeriv)\n",
    "                #print outputError\n",
    "                \n",
    "                #Backpropagation \n",
    "                # Store delta at each iteration\n",
    "                deltaStorage = [None]*(hL+1)\n",
    "                deltaStorage[hL] = outputError\n",
    "                for l in reversed(range(hL)):\n",
    "                    #print l\n",
    "                    #layer = hL-l\n",
    "                    #print layer\n",
    "                    #print np.diag(activeDerivStorage[l])\n",
    "                    \n",
    "                    #print weightStorage[l]\n",
    "                    #print np.diag(activeDerivStorage[l])\n",
    "                    #print deltaStorage[l+1]\n",
    "                    delta = np.dot(np.dot(np.diag(activeDerivStorage[l]),weightStorage[l+1]),deltaStorage[l+1])\n",
    "                    deltaStorage[l] = np.array(delta)\n",
    "                    #print deltaStorage\n",
    "                 \n",
    "                \n",
    "                for k in range(1,hL+1):\n",
    "                    weightGradient = np.outer(valueStorage[k],deltaStorage[k])\n",
    "                    biasGradient = deltaStorage[k]\n",
    "                    weightStorage[k] = weightStorage[k] - (eta*weightGradient)\n",
    "                    #print '--weight Matrices--'\n",
    "                    #print weightStorage[k]\n",
    "                    biasStorage[k] = biasStorage[k] - (eta*biasGradient)\n",
    "                    #print '--bias Vectors--'\n",
    "                    #print biasStorage[k]\n",
    "                    \n",
    "                #print biasStorage,weightStorage\n",
    "        return (weightStorage,biasStorage)\n",
    "                    \n",
    "    \n",
    "    \n",
    "    def predictNN(self,X,weight,Bias):\n",
    "        layers = len(weight)\n",
    "        inputValue = X\n",
    "        hiddenLayers = layers - 1\n",
    "        valueVector = []\n",
    "        for i in range(layers):\n",
    "            if i == 0:\n",
    "                newLayerValue = np.dot(inputValue,weight[i])+Bias[i]\n",
    "                f = np.vectorize(self.ReLU)\n",
    "                valueVector.append(f(newLayerValue))\n",
    "            else:\n",
    "                newLayerValue = np.dot(valueVector[i-1],weight[i])+Bias[i]\n",
    "                f = np.vectorize(self.ReLU)\n",
    "                valueVector.append(f(newLayerValue))\n",
    "                \n",
    "        #print valueVector        \n",
    "        #print valueVector[-1] # Get the last value in the value vector i.e. get the value from the last hidden layer\n",
    "        predProb = np.apply_along_axis(self.softmax, 1, valueVector[-1])\n",
    "        \n",
    "        #print valueVector[-1]\n",
    "        #print predProb\n",
    "        u = np.argmax(predProb,1) # get the element with the highest probability\n",
    "        pred = np.zeros((X.shape[0],predProb.shape[1]))\n",
    "        #pred\n",
    "        pred[np.arange(len(u)), u] = 1\n",
    "        return (pred)\n",
    "        \n",
    "    def ClassificationError(self,pred,y):\n",
    "        \"\"\" Provides the misclassification error given the true value and the prediction\"\"\"\n",
    "        cError = 1 - (np.count_nonzero(pred*y)/np.float(pred.shape[0]))\n",
    "        return(cError)\n",
    "                \n",
    "    def ParameterInitialization(self,X,y,nodes):\n",
    "        # Control the number of nodes in the weight initialization function\n",
    "        # nodes variable should be a list of number of nodes in each hidden layer\n",
    "        weightList = []\n",
    "        biasList = []\n",
    "        allNodes = [X.shape[1]]+nodes+[y.shape[1]]\n",
    "        \n",
    "        for i in range(1,len(allNodes)):\n",
    "            weight = np.empty([allNodes[i-1],allNodes[i]])\n",
    "            # Gaussian random weights with variance 1/sqrt(m)\n",
    "            weight = np.reshape(np.random.normal(0, 1/np.sqrt(allNodes[i-1]),weight.size), (allNodes[i-1],allNodes[i]))\n",
    "            weightList.append(weight)\n",
    "            \n",
    "            bias = np.random.normal(0,1/np.sqrt((allNodes[i])),allNodes[i])\n",
    "            biasList.append(bias)\n",
    "        return(weightList,biasList)\n",
    "            \n",
    "    \n",
    "    \n",
    "    def ReLU(self,z):\n",
    "        return np.amax([0,z])\n",
    "    \n",
    "    def softmax(self,Z):\n",
    "            #denom = sum(np.exp(Z))\n",
    "        #return(np.exp(Z)/denom)\n",
    "        e_x = np.exp(Z - np.max(Z))\n",
    "        return e_x / e_x.sum(axis=0)\n",
    "\n",
    "    \n",
    "    def ReLUDeriv(self,z):\n",
    "        if z>0:\n",
    "            Derive = 1\n",
    "        else:\n",
    "            # subgradient at zero was set to zero\n",
    "            Derive = 0\n",
    "        return(Derive)\n",
    "    \n",
    "    def softmaxDeriv(self,Z):\n",
    "        n = len(Z)\n",
    "        denom = sum(np.exp(Z))\n",
    "        \n",
    "        Jacobian = np.empty([n,n])\n",
    "        for i in range(n):\n",
    "            for j in range(i+1):\n",
    "                if i == j:\n",
    "                    Jacobian[i,j] = (np.exp(Z[i])/denom) - (np.exp(Z[i])/denom)**2\n",
    "                    Jacobian[j,i] = (np.exp(Z[i])/denom) - (np.exp(Z[i])/denom)**2\n",
    "                else:\n",
    "                    Jacobian[i,j] = (np.exp(-(Z[i]+Z[j]))/denom)**2\n",
    "                    Jacobian[j,i] = (np.exp(-(Z[i]+Z[j]))/denom)**2\n",
    "        return (Jacobian)\n",
    "                \n",
    "    def crossEntropyLoss(self, y,guess):\n",
    "        return(-(y/guess))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.94117647, -4.        , -0.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNexercise = Neuralnets(2)\n",
    "a = np.array([[2,3,4.5],[3,14.5,7]])\n",
    "#a = np.array([[2,3],[3,14.5],[4.5,7]])\n",
    "NNexercise.softmax(a)\n",
    "#print a\n",
    "np.apply_along_axis(NNexercise.softmax, 1, a)\n",
    "NNexercise.softmax(np.array([1000,40000,1]))\n",
    "NNexercise.crossEntropyLoss(np.array([1,1,0]),np.array([0.34,0.25,0.41]))\n",
    "#f = np.vectorize(NNexercise.ReLU)\n",
    "#f(([-9.6517,0.6259,0.2598]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "softmax(np.array([1000,40000,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "a = np.array([2.0,3.4,5.6,3.4,-0.1,0,-9])\n",
    "NNexercise.softmaxDeriv(a)\n",
    "NNexercise.ReLU(a.all)\n",
    "b = np.array([[2.0,3.4],[5.6,3.4],[-0.1,0],[-9,0.1]])\n",
    "f = np.vectorize(NNexercise.ReLU)  # or use a different name if you want to keep the original f\n",
    "\n",
    "#result_array = f(b) \n",
    "#result_array\n",
    "X = np.array([[-0.1,0],[-9,2]])\n",
    "y = np.array([[1,0,0],[0,1,0]])\n",
    "nodes = [4]\n",
    "Params = NNexercise.ParameterInitialization(X,y,nodes)\n",
    "#print Params[1]\n",
    "Weight,bias = NNexercise.buildNeuralNetworks(X,y,1,nodes,1000,0.01)\n",
    "#print Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "pred = NNexercise.predictNN(X,Weight,bias)\n",
    "print pred\n",
    "#print y\n",
    "#pred-y\n",
    "#np.count_nonzero(pred*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNexercise.ClassificationError(pred,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y2 = np.array([[1,0,0],[1,0,0],[0,1,0],[0,1,0]])\n",
    "pred2 = np.array([[0,1,0],[1,0,0],[0,1,0],[1,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNexercise.ClassificationError(pred2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(np.exp(a))\n",
    "\n",
    "n = len(a)\n",
    "Z = a\n",
    "denom = sum(np.exp(Z))\n",
    "        \n",
    "Jacobian = np.empty([n,n])\n",
    "for i in range(n):\n",
    "    for j in range(i+1):\n",
    "        #print i,j\n",
    "        if i == j:\n",
    "            #print (np.exp(Z[i])/denom)\n",
    "            #print (np.exp(Z[i])/denom)**2\n",
    "            Jacobian[i,j] = (np.exp(Z[i])/denom) - (np.exp(Z[i])/denom)**2\n",
    "            Jacobian[j,i] = (np.exp(Z[i])/denom) - (np.exp(Z[i])/denom)**2\n",
    "        else:\n",
    "            #print (np.exp(Z[i])/denom)\n",
    "            #print (np.exp(Z[i])/denom)**2\n",
    "            Jacobian[i,j] = (np.exp(-(Z[i]+Z[j]))/denom)**2\n",
    "            Jacobian[j,i] = (np.exp(-(Z[i]+Z[j]))/denom)**2\n",
    "\n",
    "\n",
    "#print Jacobian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the given data_3class.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pl.loadtxt('../DataFiles/HW3/data_3class.csv')\n",
    "\n",
    "\n",
    "X = train[:, 0:2]\n",
    "Y = train[:, 2:3]\n",
    "Y\n",
    "len(Y)\n",
    "Y_encode = np.int_(np.reshape(Y,(800,)))\n",
    "#print Y_encodhttp://localhost:8888/notebooks/Documents/Class-6/PythonFiles/HW3.ipynb#\n",
    "\n",
    "#plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.73176929,  0.00782698, -0.46970402],\n",
      "       [ 1.48885619, -0.82267122,  1.14324093]]), array([[ 0.49598047,  0.06429676, -0.33003664],\n",
      "       [-1.36422687,  0.49123912,  0.838899  ],\n",
      "       [ 0.03411018,  1.14214609,  0.84216352]])]\n",
      "[array([-1.19710135,  1.170064  , -0.60924974]), array([-0.97939498,  0.70415475,  1.04934362])]\n",
      "[array([[-1.19710135,  1.170064  , -0.60924974]]), array([[-0.97939498,  0.70415475,  1.04934362]])]\n",
      "[[-1.64878189  1.57572657]]\n",
      "[ 0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "b = np.zeros((len(Y_encode), 3))\n",
    "b[np.arange(len(Y_encode)), Y_encode] = 1\n",
    "b\n",
    "X_sub = np.array(X[352:353,:])\n",
    "b_sub = b[352]\n",
    "weightStorage = [np.array([[1,1,1],[1,1,1]]),np.array([[1,1,1],[1,1,1],[1,1,1]])] \n",
    "biasStorage = [np.array([-1.19710135,  1.170064  , -0.60924974]),np.array([-0.97939498,  0.70415475,  1.04934362])]\n",
    "\n",
    "weightStorage = [np.array([[ 0.73176929,  0.00782698, -0.46970402],\n",
    "       [ 1.48885619, -0.82267122,  1.14324093]]), np.array([[ 0.49598047,  0.06429676, -0.33003664],\n",
    "       [-1.36422687,  0.49123912,  0.838899  ],\n",
    "      [ 0.03411018,  1.14214609,  0.84216352]])]\n",
    "biasStorage2 = [np.array([[-1.19710135,  1.170064  , -0.60924974]]), np.array([[-0.97939498,  0.70415475,  1.04934362]])]\n",
    "print weightStorage\n",
    "print biasStorage\n",
    "print biasStorage2\n",
    "print X_sub\n",
    "print b_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NNexercise_data3 = Neuralnets(3)\n",
    "nodes = [3]\n",
    "Weight,bias = NNexercise_data3.buildNeuralNetworks(X,b,1,nodes,700,0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#NNexercise_data3 = Neuralnets(3)\n",
    "#nodes = [3]\n",
    "#Params = NNexercise_data3.ParameterInitialization(X,b,nodes)\n",
    "#print Params[0]\n",
    "#NNexercise_data3.buildNeuralNetworks(X_sub,b_sub,1,nodes,1,0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NNexercise_data3 = Neuralnets(3)\n",
    "nodes = [3]\n",
    "Params = NNexercise_data3.ParameterInitialization(X,b,nodes)\n",
    "#print Params[0]\n",
    "#Weight,bias = NNexercise_data3.buildNeuralNetworks(X,b,1,nodes,10,0.0001)\n",
    "#print bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.78669423,  0.70366009,  1.69770682,  0.11064913],\n",
       "        [ 1.39517836,  0.59081608,  0.07974418, -0.18270584]]),\n",
       " array([[ 0.32668705,  0.46909253, -0.82734596],\n",
       "        [ 0.71095772,  0.67091148, -0.91517809],\n",
       "        [-0.66544632,  0.73399975, -0.76801792],\n",
       "        [-0.15608515,  0.55759189,  1.12110288]])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = NNexercise.predictNN(X,Weight,bias)\n",
    "#pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       ..., \n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6775"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNexercise.ClassificationError(pred,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "One small  hidden layer - 3\n",
    "One large hidden layer - 50\n",
    "Two small hidden layer - [3,4]\n",
    "Two large hidden layer - [50,60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2D Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pl.loadtxt('../DataFiles/HW2/data1_train.csv')\n",
    "len(data[:,2])\n",
    "Y = data[:,2]\n",
    "Y = np.int_(np.reshape(Y,(len(Y,))))\n",
    "X = data[:,0:2]\n",
    "b = np.zeros((len(Y), 2))\n",
    "b[np.arange(len(Y)), Y] = 1\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,\n",
       "       -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,\n",
       "       -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,\n",
       "       -1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1., -1., -1.,\n",
       "       -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,\n",
       "       -1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.,\n",
       "       -1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,\n",
       "       -1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1.,\n",
       "        1., -1., -1., -1.,  1., -1., -1.,  1., -1.,  1., -1.,  1., -1.,\n",
       "       -1., -1., -1., -1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,  1., -1.,\n",
       "       -1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,\n",
       "        1., -1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,  1.,\n",
       "       -1.,  1., -1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,\n",
       "        1.,  1., -1., -1., -1., -1., -1., -1.,  1., -1.,  1.,  1., -1.,\n",
       "        1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,  1.,\n",
       "       -1.,  1.,  1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,  1.,\n",
       "        1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,\n",
       "        1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1., -1., -1., -1.,  1., -1., -1., -1.,  1.,  1., -1.,\n",
       "        1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "        1., -1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,  1., -1.,\n",
       "        1., -1., -1.,  1., -1., -1., -1.,  1., -1., -1.,  1.,  1., -1.,\n",
       "        1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "       -1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "        1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1., -1., -1.,\n",
       "       -1., -1., -1.,  1., -1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,\n",
       "        1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.,\n",
       "        1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "# 10 class digit classification\n",
    "# Atleast 200 training samples, validation and testing to be 150 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.46888017,  2.1098551 ,  1.32734838],\n",
       "       [ 1.86130614,  1.91456954,  2.64912421],\n",
       "       [ 2.47338498,  1.23116249,  1.17661799],\n",
       "       [ 1.57488247,  2.20459446,  1.87048811]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.rand(3,3)\n",
    "b = np.random.rand(3,2)\n",
    "c = np.random.rand(4,3)\n",
    "np.exp(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigArray = [[a],[b],[c]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.66995296,  0.23646859,  0.53870775],\n",
       "        [ 0.37648099,  0.56302431,  0.48723579],\n",
       "        [ 0.47250215,  0.76336075,  0.20623173],\n",
       "        [ 0.21332375,  0.99115811,  0.85635214]])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigArray[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for j in range(10,20):\n",
    "    print 20-j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.68965517,  0.45205479,  4.73684211,  0.6875    ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([2,3.3,9,2.2])\n",
    "b = np.array([2.9,7.3,1.9,3.2])\n",
    "a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.07009851e-04,   3.32808822e-03,   9.94657078e-01,\n",
       "         1.10782433e-03])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(a)/sum(np.exp(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.exp(a)/sum(np.exp(a)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Required argument 'shape' (pos 1) not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-0b2e1f483707>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Required argument 'shape' (pos 1) not found"
     ]
    }
   ],
   "source": [
    "W = np.empty()\n",
    "for a in range(5):\n",
    "    W[a] = np.rand(2,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = []\n",
    "A = np.array([[2.9,7.3],[1.9,3.2]])\n",
    "B = np.array([[2.9,7.3,23],[1.9,3.2,8]])\n",
    "W.append(A)\n",
    "W.append(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.06471074,  1.98787435,  3.13549422],\n",
       "       [ 0.64185389,  1.16315081,  2.07944154]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(W[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-174898e7ff13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "np.array(1,[2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.57735027,  0.57735027,  0.57735027],\n",
       "       [ 0.57735027,  0.57735027,  0.57735027]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.empty([2,3])\n",
    "a.fill(1/np.sqrt(3))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 4]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "s = [3]\n",
    "u = [4]\n",
    "\n",
    "b = s+[a]+u\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2. ,  3.4],\n",
       "       [ 5.6,  3.4],\n",
       "       [-0.1,  0. ],\n",
       "       [-9. ,  0.1]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 8, 27, 64, 125, 216, 343]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [None]*8\n",
    "for i in range(8):\n",
    "    A[i]=i**3\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-1a68a4662b81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "A = [None]*8\n",
    "A[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.9,  7.3],\n",
       "        [ 1.9,  3.2]]), array([[  2.9,   7.3,  23. ],\n",
       "        [  1.9,   3.2,   8. ]])]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "64\n",
      "49\n",
      "36\n",
      "25\n",
      "16\n",
      "9\n",
      "4\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "A = [i**2 for i in range(10)]\n",
    "for i in reversed(range(10)):\n",
    "    print A[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([2,3,4])\n",
    "b = np.array([2,43])\n",
    "print a.shape\n",
    "print b.shape\n",
    "A = np.outer(a,b)\n",
    "A.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.83526238, -0.40728819, -0.10133286, -0.01758712,  0.22786795,\n",
       "       -0.0959355 ,  0.43493825,  1.44427668, -0.5360688 ,  0.09329915])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(0, 1/np.sqrt(2), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'size' is an invalid keyword argument for this function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-751a85f3a634>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'size' is an invalid keyword argument for this function"
     ]
    }
   ],
   "source": [
    "np.array((np.random.normal(0, 1/np.sqrt(7), A.size)),size=(3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "total size of new array must be unchanged",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-e47c41d29d6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Divy/anaconda/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: total size of new array must be unchanged"
     ]
    }
   ],
   "source": [
    "A = np.reshape(np.random.normal(0, 1/np.sqrt(7), A.size),(4,3))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u = np.argmax(A,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = np.zeros((3,3))\n",
    "pred\n",
    "pred[np.arange(3), u] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[np.arange(3), u] = 1\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred  * pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [2,3,4,5]\n",
    "a[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9. ,  2. ],\n",
       "       [ 5.6,  3.4],\n",
       "       [ 2. ,  3.4],\n",
       "       [-0.1,  0. ]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9. ,  2. ],\n",
       "       [-0.1,  0. ],\n",
       "       [ 2. ,  3.4],\n",
       "       [ 5.6,  3.4]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "layers = 3\n",
    "for i in reversed(range(1,layers-1)):\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,layers):\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = [2,3,4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   9,  -2, 901])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A [2] - 0.5 * A [2]\n",
    "q = np.array([0,9,-2,901])\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax([0,-9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
